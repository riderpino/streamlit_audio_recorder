import "./chunk-DC5AMYBS.js";

// node_modules/react-ts-audio-recorder/dist/index.js
var VMSG_WASM_URL = "/vmsg.wasm";
var PCM_WORKLET_URL = "/pcm-worklet.js";
var DEFAULT_VMSG_WASM_URL = VMSG_WASM_URL;
async function loadPCMWorklet(audioContext, workletURL) {
  const url = workletURL || PCM_WORKLET_URL;
  await audioContext.audioWorklet.addModule(url);
}
function inlineWorker() {
  function fetchAndInstantiate(url, imports) {
    if (!WebAssembly.instantiateStreaming) return fetchAndInstantiateFallback(url, imports);
    const req = fetch(url, { credentials: "same-origin" });
    return WebAssembly.instantiateStreaming(req, imports).catch((err) => {
      if (err.message && err.message.indexOf("Argument 0 must be provided and must be a Response") > 0) {
        return fetchAndInstantiateFallback(url, imports);
      } else {
        throw err;
      }
    });
  }
  function fetchAndInstantiateFallback(url, imports) {
    return new Promise((resolve, reject) => {
      const req = new XMLHttpRequest();
      req.open("GET", url);
      req.responseType = "arraybuffer";
      req.onload = () => {
        resolve(WebAssembly.instantiate(req.response, imports));
      };
      req.onerror = reject;
      req.send();
    });
  }
  const TOTAL_STACK = 5 * 1024 * 1024;
  const TOTAL_MEMORY = 16 * 1024 * 1024;
  const WASM_PAGE_SIZE = 64 * 1024;
  let memory = null;
  let dynamicTop = TOTAL_STACK;
  function sbrk(increment) {
    const oldDynamicTop = dynamicTop;
    dynamicTop += increment;
    return oldDynamicTop;
  }
  function exit(status) {
    postMessage({ type: "internal-error", data: status });
  }
  let FFI = null;
  let ref = null;
  let pcm_l = null;
  function vmsg_init(rate) {
    ref = FFI.vmsg_init(rate);
    if (!ref) return false;
    const pcm_l_ref = new Uint32Array(memory.buffer, ref, 1)[0];
    pcm_l = new Float32Array(memory.buffer, pcm_l_ref);
    return true;
  }
  function vmsg_encode(data) {
    pcm_l.set(data);
    return FFI.vmsg_encode(ref, data.length) >= 0;
  }
  function vmsg_flush() {
    if (FFI.vmsg_flush(ref) < 0) return null;
    const mp3_ref = new Uint32Array(memory.buffer, ref + 4, 1)[0];
    const size = new Uint32Array(memory.buffer, ref + 8, 1)[0];
    const mp3 = new Uint8Array(memory.buffer, mp3_ref, size);
    const blob = new Blob([mp3], { type: "audio/mpeg" });
    FFI.vmsg_free(ref);
    ref = null;
    pcm_l = null;
    return blob;
  }
  function testSafariWebAssemblyBug() {
    const bin = new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 6, 1, 96, 1, 127, 1, 127, 3, 2, 1, 0, 5, 3, 1, 0, 1, 7, 8, 1, 4, 116, 101, 115, 116, 0, 0, 10, 16, 1, 14, 0, 32, 0, 65, 1, 54, 2, 0, 32, 0, 40, 2, 0, 11]);
    const mod = new WebAssembly.Module(bin);
    const inst = new WebAssembly.Instance(mod, {});
    return inst.exports.test(4) !== 0;
  }
  onmessage = (e) => {
    const msg = e.data;
    switch (msg.type) {
      case "init":
        const { wasmURL, shimURL } = msg.data;
        Promise.resolve().then(() => {
          if (self.WebAssembly && !testSafariWebAssemblyBug()) {
            delete self.WebAssembly;
          }
          if (!self.WebAssembly && shimURL) {
            importScripts(shimURL);
          }
          memory = new WebAssembly.Memory({
            initial: TOTAL_MEMORY / WASM_PAGE_SIZE,
            maximum: TOTAL_MEMORY / WASM_PAGE_SIZE
          });
          return {
            memory,
            pow: Math.pow,
            exit,
            powf: Math.pow,
            exp: Math.exp,
            sqrtf: Math.sqrt,
            cos: Math.cos,
            log: Math.log,
            sin: Math.sin,
            sbrk
          };
        }).then((Runtime) => {
          return fetchAndInstantiate(wasmURL, { env: Runtime });
        }).then((wasm) => {
          FFI = wasm.instance.exports;
          postMessage({ type: "init", data: null });
        }).catch((err) => {
          postMessage({ type: "init-error", data: err.toString() });
        });
        break;
      case "start":
        if (!vmsg_init(msg.data)) return postMessage({ type: "error", data: "vmsg_init" });
        break;
      case "data":
        if (!vmsg_encode(msg.data)) return postMessage({ type: "error", data: "vmsg_encode" });
        break;
      case "stop":
        const blob = vmsg_flush();
        if (!blob) return postMessage({ type: "error", data: "vmsg_flush" });
        postMessage({ type: "stop", data: blob });
        break;
    }
  };
}
var Recorder = class {
  constructor(opts = {}, onStop = null) {
    const base = typeof location !== "undefined" ? location.href : "http://localhost";
    this.wasmURL = new URL(opts.wasmURL || "/static/js/vmsg.wasm", base).href;
    this.shimURL = opts.shimURL ? new URL(opts.shimURL, base).href : null;
    this.onStop = onStop;
    this.pitch = opts.pitch || 0;
    this.stream = null;
    this.audioCtx = null;
    this.gainNode = null;
    this.pitchFX = null;
    this.encNode = null;
    this.worker = null;
    this.workerURL = null;
    this.blob = null;
    this.blobURL = null;
    this.resolve = null;
    this.reject = null;
    Object.seal(this);
  }
  close() {
    if (this.encNode) this.encNode.disconnect();
    if (this.encNode) this.encNode.onaudioprocess = null;
    if (this.stream) this.stopTracks();
    if (this.audioCtx) this.audioCtx.close();
    if (this.worker) {
      this.worker.terminate();
      this.worker = null;
    }
    if (this.workerURL) URL.revokeObjectURL(this.workerURL);
    if (this.blobURL) URL.revokeObjectURL(this.blobURL);
  }
  // Without pitch shift:
  //   [sourceNode] -> [gainNode] -> [encNode] -> [audioCtx.destination]
  //                                     |
  //                                     -> [worker]
  // With pitch shift:
  //   [sourceNode] -> [gainNode] -> [pitchFX] -> [encNode] -> [audioCtx.destination]
  //                                                  |
  //                                                  -> [worker]
  initAudio() {
    const getUserMedia = navigator.mediaDevices && navigator.mediaDevices.getUserMedia ? function(constraints) {
      return navigator.mediaDevices.getUserMedia(constraints);
    } : function(constraints) {
      const oldGetUserMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
      if (!oldGetUserMedia) {
        return Promise.reject(new Error("getUserMedia is not implemented in this browser"));
      }
      return new Promise(function(resolve, reject) {
        oldGetUserMedia.call(navigator, constraints, resolve, reject);
      });
    };
    return getUserMedia({ audio: true }).then((stream) => {
      this.stream = stream;
      const audioCtx = this.audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const sourceNode = audioCtx.createMediaStreamSource(stream);
      const gainNode = this.gainNode = (audioCtx.createGain || audioCtx.createGainNode).call(audioCtx);
      gainNode.gain.value = 1;
      sourceNode.connect(gainNode);
      const pitchFX = this.pitchFX = new Jungle(audioCtx);
      pitchFX.setPitchOffset(this.pitch);
      const encNode = this.encNode = (audioCtx.createScriptProcessor || audioCtx.createJavaScriptNode).call(audioCtx, 0, 1, 1);
      pitchFX.output.connect(encNode);
      gainNode.connect(this.pitch === 0 ? encNode : pitchFX.input);
    });
  }
  initWorker() {
    if (this.worker) return Promise.resolve();
    const blob = new Blob(
      ["(", inlineWorker.toString(), ")()"],
      { type: "application/javascript" }
    );
    const workerURL = this.workerURL = URL.createObjectURL(blob);
    const worker = this.worker = new Worker(workerURL);
    const { wasmURL, shimURL } = this;
    worker.postMessage({ type: "init", data: { wasmURL, shimURL } });
    return new Promise((resolve, reject) => {
      worker.onmessage = (e) => {
        const msg = e.data;
        switch (msg.type) {
          case "init":
            resolve();
            break;
          case "init-error":
            this.close();
            reject(new Error(msg.data));
            break;
          // TODO(Kagami): Error handling.
          case "error":
          case "internal-error":
            this.close();
            console.error("Worker error:", msg.data);
            if (this.reject) this.reject(msg.data);
            break;
          case "stop":
            this.blob = msg.data;
            this.blobURL = URL.createObjectURL(msg.data);
            if (this.onStop) this.onStop();
            if (this.resolve) this.resolve(this.blob);
            break;
        }
      };
    });
  }
  init() {
    return this.initAudio().then(this.initWorker.bind(this));
  }
  startRecording() {
    if (!this.stream) throw new Error("missing audio initialization");
    if (!this.worker) throw new Error("missing worker initialization");
    this.blob = null;
    if (this.blobURL) URL.revokeObjectURL(this.blobURL);
    this.blobURL = null;
    this.resolve = null;
    this.reject = null;
    this.worker.postMessage({ type: "start", data: this.audioCtx.sampleRate });
    this.encNode.onaudioprocess = (e) => {
      const samples = e.inputBuffer.getChannelData(0);
      this.worker.postMessage({ type: "data", data: samples });
    };
    this.encNode.connect(this.audioCtx.destination);
  }
  stopRecording() {
    if (!this.stream) throw new Error("missing audio initialization");
    if (!this.worker) throw new Error("missing worker initialization");
    this.encNode.disconnect();
    this.encNode.onaudioprocess = null;
    this.stopTracks();
    this.audioCtx.close();
    this.worker.postMessage({ type: "stop", data: null });
    return new Promise((resolve, reject) => {
      this.resolve = resolve;
      this.reject = reject;
    });
  }
  stopTracks() {
    if (this.stream.getTracks) {
      this.stream.getTracks().forEach((track) => track.stop());
    }
  }
};
var delayTime = 0.1;
var fadeTime = 0.05;
var bufferTime = 0.1;
function createFadeBuffer(context, activeTime, fadeTime2) {
  var length1 = activeTime * context.sampleRate;
  var length2 = (activeTime - 2 * fadeTime2) * context.sampleRate;
  var length = length1 + length2;
  var buffer = context.createBuffer(1, length, context.sampleRate);
  var p = buffer.getChannelData(0);
  var fadeLength = fadeTime2 * context.sampleRate;
  var fadeIndex1 = fadeLength;
  var fadeIndex2 = length1 - fadeLength;
  for (var i = 0; i < length1; ++i) {
    var value;
    if (i < fadeIndex1) {
      value = Math.sqrt(i / fadeLength);
    } else if (i >= fadeIndex2) {
      value = Math.sqrt(1 - (i - fadeIndex2) / fadeLength);
    } else {
      value = 1;
    }
    p[i] = value;
  }
  for (var i = length1; i < length; ++i) {
    p[i] = 0;
  }
  return buffer;
}
function createDelayTimeBuffer(context, activeTime, fadeTime2, shiftUp) {
  var length1 = activeTime * context.sampleRate;
  var length2 = (activeTime - 2 * fadeTime2) * context.sampleRate;
  var length = length1 + length2;
  var buffer = context.createBuffer(1, length, context.sampleRate);
  var p = buffer.getChannelData(0);
  for (var i = 0; i < length1; ++i) {
    if (shiftUp)
      p[i] = (length1 - i) / length;
    else
      p[i] = i / length1;
  }
  for (var i = length1; i < length; ++i) {
    p[i] = 0;
  }
  return buffer;
}
function Jungle(context) {
  this.context = context;
  var input = (context.createGain || context.createGainNode).call(context);
  var output = (context.createGain || context.createGainNode).call(context);
  this.input = input;
  this.output = output;
  var mod1 = context.createBufferSource();
  var mod2 = context.createBufferSource();
  var mod3 = context.createBufferSource();
  var mod4 = context.createBufferSource();
  this.shiftDownBuffer = createDelayTimeBuffer(context, bufferTime, fadeTime, false);
  this.shiftUpBuffer = createDelayTimeBuffer(context, bufferTime, fadeTime, true);
  mod1.buffer = this.shiftDownBuffer;
  mod2.buffer = this.shiftDownBuffer;
  mod3.buffer = this.shiftUpBuffer;
  mod4.buffer = this.shiftUpBuffer;
  mod1.loop = true;
  mod2.loop = true;
  mod3.loop = true;
  mod4.loop = true;
  var mod1Gain = (context.createGain || context.createGainNode).call(context);
  var mod2Gain = (context.createGain || context.createGainNode).call(context);
  var mod3Gain = (context.createGain || context.createGainNode).call(context);
  mod3Gain.gain.value = 0;
  var mod4Gain = (context.createGain || context.createGainNode).call(context);
  mod4Gain.gain.value = 0;
  mod1.connect(mod1Gain);
  mod2.connect(mod2Gain);
  mod3.connect(mod3Gain);
  mod4.connect(mod4Gain);
  var modGain1 = (context.createGain || context.createGainNode).call(context);
  var modGain2 = (context.createGain || context.createGainNode).call(context);
  var delay1 = (context.createDelay || context.createDelayNode).call(context);
  var delay2 = (context.createDelay || context.createDelayNode).call(context);
  mod1Gain.connect(modGain1);
  mod2Gain.connect(modGain2);
  mod3Gain.connect(modGain1);
  mod4Gain.connect(modGain2);
  modGain1.connect(delay1.delayTime);
  modGain2.connect(delay2.delayTime);
  var fade1 = context.createBufferSource();
  var fade2 = context.createBufferSource();
  var fadeBuffer = createFadeBuffer(context, bufferTime, fadeTime);
  fade1.buffer = fadeBuffer;
  fade2.buffer = fadeBuffer;
  fade1.loop = true;
  fade2.loop = true;
  var mix1 = (context.createGain || context.createGainNode).call(context);
  var mix2 = (context.createGain || context.createGainNode).call(context);
  mix1.gain.value = 0;
  mix2.gain.value = 0;
  fade1.connect(mix1.gain);
  fade2.connect(mix2.gain);
  input.connect(delay1);
  input.connect(delay2);
  delay1.connect(mix1);
  delay2.connect(mix2);
  mix1.connect(output);
  mix2.connect(output);
  var t = context.currentTime + 0.05;
  var t2 = t + bufferTime - fadeTime;
  mod1.start(t);
  mod2.start(t2);
  mod3.start(t);
  mod4.start(t2);
  fade1.start(t);
  fade2.start(t2);
  this.mod1 = mod1;
  this.mod2 = mod2;
  this.mod1Gain = mod1Gain;
  this.mod2Gain = mod2Gain;
  this.mod3Gain = mod3Gain;
  this.mod4Gain = mod4Gain;
  this.modGain1 = modGain1;
  this.modGain2 = modGain2;
  this.fade1 = fade1;
  this.fade2 = fade2;
  this.mix1 = mix1;
  this.mix2 = mix2;
  this.delay1 = delay1;
  this.delay2 = delay2;
  this.setDelay(delayTime);
}
Jungle.prototype.setDelay = function(delayTime2) {
  this.modGain1.gain.setTargetAtTime(0.5 * delayTime2, 0, 0.01);
  this.modGain2.gain.setTargetAtTime(0.5 * delayTime2, 0, 0.01);
};
Jungle.prototype.setPitchOffset = function(mult) {
  if (mult > 0) {
    this.mod1Gain.gain.value = 0;
    this.mod2Gain.gain.value = 0;
    this.mod3Gain.gain.value = 1;
    this.mod4Gain.gain.value = 1;
  } else {
    this.mod1Gain.gain.value = 1;
    this.mod2Gain.gain.value = 1;
    this.mod3Gain.gain.value = 0;
    this.mod4Gain.gain.value = 0;
  }
  this.setDelay(delayTime * Math.abs(mult));
};
function writeString(view, offset, string) {
  for (let i = 0; i < string.length; i++) {
    view.setUint8(offset + i, string.charCodeAt(i));
  }
}
function floatTo16BitPCM(view, offset, input) {
  for (let i = 0; i < input.length; i++, offset += 2) {
    const s = Math.max(-1, Math.min(1, input[i]));
    view.setInt16(offset, s < 0 ? s * 32768 : s * 32767, true);
  }
}
function mergeFloat32Arrays(arrays) {
  const totalLength = arrays.reduce((sum, arr) => sum + arr.length, 0);
  const result = new Float32Array(totalLength);
  let offset = 0;
  for (const arr of arrays) {
    result.set(arr, offset);
    offset += arr.length;
  }
  return result;
}
function encodeWav(samples, sampleRate) {
  const buffer = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buffer);
  writeString(view, 0, "RIFF");
  view.setUint32(4, 36 + samples.length * 2, true);
  writeString(view, 8, "WAVE");
  writeString(view, 12, "fmt ");
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true);
  view.setUint16(22, 1, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * 2, true);
  view.setUint16(32, 2, true);
  view.setUint16(34, 16, true);
  writeString(view, 36, "data");
  view.setUint32(40, samples.length * 2, true);
  floatTo16BitPCM(view, 44, samples);
  return new Blob([view], { type: "audio/wav" });
}
var MultiRecorder = class {
  constructor(options) {
    this.mp3Recorder = null;
    this.wavStream = null;
    this.wavAudioCtx = null;
    this.wavProcessor = null;
    this.wavPcmData = [];
    this.format = options.format;
    this.sampleRate = options.sampleRate || 48e3;
    this.wasmURL = options.wasmURL;
    this.shimURL = options.shimURL;
    this.pitch = options.pitch || 0;
    this.workletURL = options.workletURL;
  }
  async init() {
    if (this.format === "mp3") {
      this.mp3Recorder = new Recorder({
        wasmURL: this.wasmURL || "/static/js/vmsg.wasm",
        shimURL: this.shimURL,
        pitch: this.pitch
      });
      await this.mp3Recorder.init();
    } else if (this.format === "wav") {
      this.wavPcmData = [];
    }
  }
  async startRecording() {
    if (this.format === "mp3") {
      if (!this.mp3Recorder) {
        throw new Error("MP3 recorder not initialized. Call init() first.");
      }
      this.mp3Recorder.startRecording();
    } else if (this.format === "wav") {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      this.wavStream = stream;
      const audioCtx = new AudioContext({ sampleRate: this.sampleRate });
      this.wavAudioCtx = audioCtx;
      const workletUrl = this.workletURL || PCM_WORKLET_URL;
      await audioCtx.audioWorklet.addModule(workletUrl);
      const source = audioCtx.createMediaStreamSource(stream);
      const processor = new AudioWorkletNode(audioCtx, "pcm-processor");
      processor.port.onmessage = (e) => {
        const channelData = e.data;
        if (channelData && channelData.length > 0) {
          this.wavPcmData.push(new Float32Array(channelData));
        }
      };
      source.connect(processor);
      processor.connect(audioCtx.destination);
      this.wavProcessor = processor;
    }
  }
  async stopRecording() {
    if (this.format === "mp3") {
      if (!this.mp3Recorder) {
        throw new Error("MP3 recorder not initialized.");
      }
      const blob = await this.mp3Recorder.stopRecording();
      this.mp3Recorder.close();
      this.mp3Recorder = null;
      return blob;
    } else if (this.format === "wav") {
      if (!this.wavProcessor || !this.wavAudioCtx || !this.wavStream) {
        throw new Error("WAV recorder not initialized.");
      }
      if (this.wavProcessor) {
        this.wavProcessor.disconnect();
      }
      if (this.wavStream && this.wavStream.getTracks) {
        this.wavStream.getTracks().forEach((track) => track.stop());
      }
      const mergedSamples = mergeFloat32Arrays(this.wavPcmData);
      const blob = encodeWav(mergedSamples, this.sampleRate);
      this.wavPcmData = [];
      return blob;
    }
    throw new Error(`Unknown format: ${this.format}`);
  }
  close() {
    if (this.format === "mp3" && this.mp3Recorder) {
      this.mp3Recorder.close();
      this.mp3Recorder = null;
    } else if (this.format === "wav") {
      if (this.wavProcessor) {
        try {
          this.wavProcessor.port.close();
          this.wavProcessor.disconnect();
        } catch (e) {
        }
        this.wavProcessor = null;
      }
      if (this.wavStream && this.wavStream.getTracks) {
        this.wavStream.getTracks().forEach((track) => track.stop());
        this.wavStream = null;
      }
      if (this.wavAudioCtx && this.wavAudioCtx.state !== "closed") {
        this.wavAudioCtx.close().catch(() => {
        });
      }
      this.wavAudioCtx = null;
      this.wavPcmData = [];
    }
  }
};
export {
  DEFAULT_VMSG_WASM_URL,
  MultiRecorder,
  PCM_WORKLET_URL,
  VMSG_WASM_URL,
  loadPCMWorklet
};
//# sourceMappingURL=react-ts-audio-recorder.js.map
